{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66799a02-f6b4-4ebe-8890-867d1f2c53e3",
   "metadata": {},
   "source": [
    "# *SDS_Benchmark*: Compare satellite-derived shoreline to groundtruth\n",
    "\n",
    "\n",
    "This notebook shows how to compare the satellite-derived shorelines from the different submissions at the 4 different sites:\n",
    "- Narrabeen, Australia [ref](https://www.nature.com/articles/sdata201624)\n",
    "- Duck, North Carolina, USA [ref](https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1002/2014JC010329)\n",
    "- Truc Vert, France [ref](https://www.nature.com/articles/s41597-020-00750-5#Tab2)\n",
    "- Torrey Pines, California, USA [ref](https://www.nature.com/articles/s41597-019-0167-6)\n",
    "\n",
    "## Initial settings\n",
    "\n",
    "To run this notebook you will need basic Python packages installed: `numpy`, `scipy`, `pandas`, `matplotlib`, `pytz`.\n",
    "\n",
    "If you have [CoastSat](https://github.com/kvos/CoastSat) installed, you can activate that envrionment as it has all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df4f15e-1516-4ec9-87c6-681fe18ceb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmark datasets available:\n",
      "['CALAMILLOR', 'DUCK', 'NARRABEEN', 'TORREYPINES', 'TRUCVERT']\n",
      "\n",
      "Loaded sites_info.txt.\n",
      "NARRABEEN: {'beach_slope': 0.1, 'contour_level': 0.7, 'epsg': 28356}\n",
      "DUCK: {'beach_slope': 0.1, 'contour_level': 0.585, 'epsg': 32119}\n",
      "TRUCVERT: {'beach_slope': 0.05, 'contour_level': 1.5, 'epsg': 32630}\n",
      "TORREYPINES: {'beach_slope': 0.045, 'contour_level': 0.792, 'epsg': 26946}\n",
      "CALAMILLOR: {'beach_slope': 0.1, 'contour_level': 0, 'epsg': 2062}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "plt.ion()\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import interpolate\n",
    "from scipy import stats\n",
    "import pytz\n",
    "import json\n",
    "import pdb\n",
    "# import utils module located in the repository (utils.py)\n",
    "import utils\n",
    "\n",
    "# filepaths to all the datasets\n",
    "fp_datasets = os.path.join(os.path.join(os.getcwd(),'datasets'))\n",
    "names_datasets = os.listdir(fp_datasets)\n",
    "names_datasets = [_ for _ in names_datasets if _ not in ['README.md','sites_info.txt']]\n",
    "print('\\nBenchmark datasets available:\\n%s'%(names_datasets))\n",
    "                \n",
    "# load site info dict if exists or create\n",
    "fp_info = os.path.join(fp_datasets,'sites_info.txt')\n",
    "if os.path.exists(fp_info):\n",
    "    with open(fp_info,'r') as f: sites_info = json.load(f)  \n",
    "    print('\\nLoaded sites_info.txt.')\n",
    "    for key in sites_info.keys(): print('%s: %s'%(key,sites_info[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f19c0-ef75-4008-a7d4-4324c3eec22c",
   "metadata": {},
   "source": [
    "### Plot satellite-derived shoreline time-series against in situ surveys\n",
    "\n",
    "Select your submission name and this section will plot the time-series against the in situ data. Change the following parameters to your own submission:\n",
    "- `submission_name`: name of the team (e.g., team_COASTSAT)\n",
    "- `submission_type`: level of processing of the shoreline time-series (`raw_timeseries` or `tidally_corrected_timeseries`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8576dbe6-7867-442e-9c6d-a326ada1ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission team name\n",
    "submission_name = 'team_COASTSAT'\n",
    "# type of submission (tidally-corected_timeseries or raw_timeseries)\n",
    "submission_type = 'tidally_corrected_timeseries'\n",
    "submission_folder = os.path.join(os.getcwd(),'submissions',submission_name)\n",
    "submission_sites = os.listdir(submission_folder)\n",
    "# create folder to store comparisons\n",
    "output_folder = os.path.join(submission_folder,'comparison_%s'%submission_type)\n",
    "if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "# selected transects for comparison with groundtruth\n",
    "selected_transects = {\n",
    "    'NARRABEEN': ['PF1','PF2','PF4','PF6','PF8'],\n",
    "    'DUCK':      ['-91','1','1006','1097'],\n",
    "    'TRUCVERT':   ['-400','-300','-200','-100'],\n",
    "    'TORREYPINES':['PF525','PF535','PF585','PF595'],    \n",
    "    }\n",
    "# loop through sites\n",
    "for sitename in names_datasets:\n",
    "    if sitename not in submission_sites: continue\n",
    "    # load satellite time-series\n",
    "    fp_tc_timeseries = os.path.join(submission_folder,sitename,submission_type)\n",
    "    fn_transects = os.listdir(fp_tc_timeseries)\n",
    "    transects = selected_transects[sitename]\n",
    "    # load groundtruth\n",
    "    data_folder = os.path.join(fp_datasets,sitename)\n",
    "    with open(os.path.join(data_folder, '%s_groundtruth.pkl'%sitename), 'rb') as f:\n",
    "        gt = pickle.load(f)  \n",
    "    # make plot comparing the time-series\n",
    "    fig = plt.figure(figsize=[15,8], tight_layout=True)\n",
    "    fig.suptitle('Time-series of shoreline change at %s ( %.2fm contour)'%(sitename,sites_info[sitename]['contour_level']))\n",
    "    gs = gridspec.GridSpec(len(transects),1)\n",
    "    gs.update(left=0.05, right=0.95, bottom=0.05, top=0.95, hspace=0.15)\n",
    "    for i,key in enumerate(transects):\n",
    "        fn = os.path.join(fp_tc_timeseries,'%s_timeseries_tidally_corrected.csv'%key)\n",
    "        df = pd.read_csv(fn,sep=',',parse_dates=['dates'])  \n",
    "        chainage = np.array(df[key])\n",
    "        dates_sat = [_.to_pydatetime() for _ in df['dates']]\n",
    "        # remove nans\n",
    "        idx_nan = np.isnan(chainage)\n",
    "        dates_nonan = [dates_sat[_] for _ in np.where(~idx_nan)[0]]\n",
    "        chainage = chainage[~idx_nan]\n",
    "        # compute shoreline monthly averages\n",
    "        dict_month, dates_month, chainage_month, list_month = utils.monthly_average(dates_nonan, chainage)\n",
    "        # plot time-series\n",
    "        ax = fig.add_subplot(gs[i,0])\n",
    "        ax.plot(gt[key]['dates'], gt[key]['chainages'],'C1-',label='in situ')\n",
    "        ax.grid(b=True,linestyle=':', color='0.5')\n",
    "        ax.plot(dates_nonan, chainage,'+', lw=1, color='C0', mfc='w', ms=4, alpha=0.5,label='raw datapoints')\n",
    "        ax.plot(dates_month, chainage_month, '-', lw=1.5, color='C0', mfc='w', ms=4, label='monthly-averaged')\n",
    "        ax.set_ylabel('distance [m]', fontsize=12)\n",
    "        ax.text(0.1,0.95, key, bbox=dict(boxstyle=\"square\", ec='k',fc='w'), ha='center',\n",
    "                va='top', transform=ax.transAxes, fontsize=14) \n",
    "        if i == 0: ax.legend(loc='lower left')\n",
    "    fig.savefig(os.path.join(output_folder,'%s_comparison.jpg'%sitename),dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7636b07-bc0c-4c8d-a37b-b4aac92d362f",
   "metadata": {},
   "source": [
    "### Accuracy assessment of the satellite-derived shoreline time-series\n",
    "\n",
    "This section evaluate the horizontal accuracy of the satellite-derived time-series of shoreline change.\n",
    "The user can select the transects over which to evaluate the time-series and a few parameters for the assessment:\n",
    "- `min_days`: 3 days (default), number of days over which it can be assumed that the shoreline has not change. If a survey is located within this time window, it is compared directly to the satellite shorelines.\n",
    "- `max_days`: 10 days (default), number of days after which a comparison is not realistic any more due to shoreline changes. Between `min_days` and `max_days`, the surveyed shoreline time-series are interpolated to match the date of the satellite shoreline points.\n",
    "\n",
    "There are also 2 visualisation parameters, the `binwidth` to use when plotting the histogram distributions and the limits (`lims`) over which to plot the errors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80b06d2-2ba7-4d06-81ec-463364bb1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission team name\n",
    "submission_name = 'team_COASTSAT'\n",
    "# type of submission (tidally-corected_timeseries or raw_timeseries)\n",
    "submission_type = 'tidally_corrected_timeseries'\n",
    "submission_folder = os.path.join(os.getcwd(),'submissions',submission_name)\n",
    "submission_sites = os.listdir(submission_folder)\n",
    "# create folder to store comparisons\n",
    "output_folder = os.path.join(submission_folder,'evaluation_%s'%submission_type)\n",
    "if not os.path.exists(output_folder): os.makedirs(output_folder)\n",
    "transect_folder = os.path.join(output_folder,'by_transect')\n",
    "if not os.path.exists(transect_folder): os.makedirs(transect_folder)\n",
    "# selected transects for comparison with groundtruth\n",
    "selected_transects = {\n",
    "    'NARRABEEN': ['PF1','PF2','PF4','PF6','PF8'],\n",
    "    'DUCK':      ['-91','1','1006','1097'],\n",
    "    'TRUCVERT':   ['-400','-300','-200','-100'],\n",
    "    'TORREYPINES':['PF525','PF535','PF585','PF595'],    \n",
    "    }\n",
    "# parameters for evaluation\n",
    "settings = {\n",
    "    'min_days':  3,           # numbers of days difference under which to use nearest neighbour interpolation\n",
    "    'max_days':  10,          # maximum number of days difference to do a comparison\n",
    "    'binwidth':  3,           # binwidth for histogram plotting\n",
    "    'lims':      [-50,50]     # cross-shore change limits for plotting purposes\n",
    "           }\n",
    "# loop through sites\n",
    "for sitename in names_datasets:\n",
    "    if sitename not in submission_sites: continue\n",
    "    # load groundtruth\n",
    "    data_folder = os.path.join(fp_datasets,sitename)\n",
    "    with open(os.path.join(data_folder, '%s_groundtruth.pkl'%sitename), 'rb') as f:\n",
    "        gt = pickle.load(f) \n",
    "    # load satellite time-series\n",
    "    fp_tc_timeseries = os.path.join(submission_folder,sitename,submission_type)\n",
    "    fn_transects = os.listdir(fp_tc_timeseries)\n",
    "    transects = selected_transects[sitename]\n",
    "    # evaluate the time-series along each transect\n",
    "    chain_sat_all, chain_sur_all, satnames_all = [], [], []\n",
    "    for key in transects:\n",
    "        # load satellite time-series\n",
    "        fp_ts = os.path.join(fp_tc_timeseries,'%s_timeseries_tidally_corrected.csv'%key)\n",
    "        ts = pd.read_csv(fp_ts,parse_dates=['dates'])\n",
    "        ts_sat, ts_sur, satnames, fig = utils.compare_timeseries(ts,gt,key,settings)\n",
    "        fig.savefig(os.path.join(transect_folder,'%s_transect_%s.jpg'%(sitename,key)), dpi=200)\n",
    "        plt.close(fig)\n",
    "        chain_sat_all = np.append(chain_sat_all,ts_sat)\n",
    "        chain_sur_all = np.append(chain_sur_all,ts_sur)\n",
    "        satnames_all = satnames_all + satnames \n",
    "    # calculate statistics for all transects together\n",
    "    chain_error = chain_sat_all - chain_sur_all\n",
    "    slope, intercept, rvalue, pvalue, std_err = stats.linregress(chain_sur_all, chain_sat_all)\n",
    "    R2 = rvalue**2\n",
    "    rmse = np.sqrt(np.mean((chain_error)**2))\n",
    "    mean = np.mean(chain_error)\n",
    "    std = np.std(chain_error)\n",
    "    q90 = np.percentile(np.abs(chain_error), 90)\n",
    "    fig,ax = plt.subplots(1,2,figsize=(15,5), tight_layout=True)\n",
    "    # histogram\n",
    "    ax[0].grid(which='major',linestyle=':',color='0.5')\n",
    "    ax[0].axvline(x=0, ls='--', lw=1.5, color='k')\n",
    "    binwidth = settings['binwidth']\n",
    "    bins = np.arange(min(chain_error), max(chain_error) + binwidth, binwidth)\n",
    "    density = ax[0].hist(chain_error, bins=bins, density=True, color='0.6', edgecolor='k', alpha=0.5)\n",
    "    mu, std = stats.norm.fit(chain_error)\n",
    "    pval = stats.normaltest(chain_error)[1]\n",
    "    xlims = settings['lims']\n",
    "    x = np.linspace(xlims[0], xlims[1], 100)\n",
    "    p = stats.norm.pdf(x, mu, std)\n",
    "    ax[0].plot(x, p, 'r-', linewidth=1)\n",
    "    ax[0].set(xlabel='error [m]', ylabel='pdf', xlim=settings['lims'], title=sitename)\n",
    "    str_stats = ' rmse = %.1f\\n mean = %.1f\\n std = %.1f\\n q90 = %.1f' % (rmse, mean, std, q90)\n",
    "    ax[0].text(0, 0.98, str_stats,va='top', transform=ax[0].transAxes,fontsize=14)\n",
    "    # boxplot\n",
    "    data = []\n",
    "    median_data = []\n",
    "    n_data = []\n",
    "    ax[1].yaxis.grid()\n",
    "    for k,sat in enumerate(list(np.unique(satnames_all))):\n",
    "        idx = np.where([_ == sat for _ in satnames_all])[0]\n",
    "        data.append(chain_error[idx])\n",
    "        median_data.append(np.median(chain_error[idx]))\n",
    "        n_data.append(len(chain_error[idx]))\n",
    "    bp = ax[1].boxplot(data,0,'k.', labels=list(np.unique(satnames_all)), patch_artist=True)\n",
    "    for median in bp['medians']:\n",
    "        median.set(color='k', linewidth=1.5)\n",
    "    for j,boxes in enumerate(bp['boxes']):\n",
    "        boxes.set(facecolor='C'+str(j))\n",
    "        ax[1].text(j+1,median_data[j]+1, '%.1f' % median_data[j], horizontalalignment='center', fontsize=14)\n",
    "        ax[1].text(j+1+0.35,median_data[j]+1, ('n=%.d' % int(n_data[j])), ha='center', va='center', fontsize=12, rotation='vertical')\n",
    "    ax[1].set(ylabel='error [m]', ylim=settings['lims']);\n",
    "    fig.savefig(os.path.join(output_folder,'%s_evaluation.jpg'%(sitename)), dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('gdal_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b4a0c50a2c05fddc92d9ecb1a92bd945e19b26e2b02ce294bc84549fb23da1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
